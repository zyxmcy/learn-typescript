(window.webpackJsonp=window.webpackJsonp||[]).push([[17],{439:function(e,a,s){"use strict";s.r(a);var t=s(2),n=Object(t.a)({},(function(){var e=this,a=e._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("p"),a("div",{staticClass:"table-of-contents"},[a("ul",[a("li",[a("a",{attrs:{href:"#clickhouse是一种高性能的列式数据库管理系统-支持各种不同类型的表引擎。以下是clickhouse中常用的表引擎"}},[e._v("ClickHouse是一种高性能的列式数据库管理系统，支持各种不同类型的表引擎。以下是ClickHouse中常用的表引擎")])]),a("li",[a("a",{attrs:{href:"#hdfs-hadoop-distributed-file-system-是适合存储大型数据集的分布式文件系统"}},[e._v("HDFS（Hadoop Distributed File System）是适合存储大型数据集的分布式文件系统")])]),a("li",[a("a",{attrs:{href:"#对于数据仓库的理解"}},[e._v("对于数据仓库的理解")])]),a("li",[a("a",{attrs:{href:"#hive-内部表和外部表之间的一些区别"}},[e._v("Hive 内部表和外部表之间的一些区别")])]),a("li",[a("a",{attrs:{href:"#hive-sql有哪三种分组排序-他们各自的特点是什么"}},[e._v("Hive SQL有哪三种分组排序，他们各自的特点是什么")])]),a("li",[a("a",{attrs:{href:"#udf-udaf-udtf-它们的区别是什么-请问它们分别解决了什么问题"}},[e._v("UDF/UDAF/UDTF，它们的区别是什么，请问它们分别解决了什么问题")])]),a("li",[a("a",{attrs:{href:"#某些job运行时间较长可能是由于以下几个原因造成的"}},[e._v("某些Job运行时间较长可能是由于以下几个原因造成的")])]),a("li",[a("a",{attrs:{href:"#如何解决数据倾斜问题"}},[e._v("如何解决数据倾斜问题")])]),a("li",[a("a",{attrs:{href:"#hive分区表的作用是什么-是否越多越好"}},[e._v("Hive分区表的作用是什么，是否越多越好")])]),a("li",[a("a",{attrs:{href:"#flink有哪些时间语义-有哪些使用场景"}},[e._v("Flink有哪些时间语义，有哪些使用场景？")])]),a("li",[a("a",{attrs:{href:"#hdfs数据存储小文件问题"}},[e._v("HDFS数据存储小文件问题")])])])]),a("p"),e._v(" "),a("h2",{attrs:{id:"clickhouse是一种高性能的列式数据库管理系统-支持各种不同类型的表引擎。以下是clickhouse中常用的表引擎"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#clickhouse是一种高性能的列式数据库管理系统-支持各种不同类型的表引擎。以下是clickhouse中常用的表引擎"}},[e._v("#")]),e._v(" ClickHouse是一种高性能的列式数据库管理系统，支持各种不同类型的表引擎。以下是ClickHouse中常用的表引擎")]),e._v(" "),a("ol",[a("li",[a("p",[e._v("MergeTree：这是ClickHouse的默认表引擎，它使用了基于LSM（Log-Structured Merge）树的存储引擎，适用于范围查询和大批量数据插入。")])]),e._v(" "),a("li",[a("p",[e._v("Distributed：这是一种分布式表引擎，可在多个节点上分布数据以提高性能和容错能力。此引擎可以将数据分散到多个节点上，并支持跨节点的复杂查询。")])]),e._v(" "),a("li",[a("p",[e._v("ReplacingMergeTree：这是一种特殊的MergeTree表引擎，它允许在相同的主键下更新数据，而不是创建新的行。该引擎通常用于日志记录或其他需要频繁更新的应用程序。")])]),e._v(" "),a("li",[a("p",[e._v("SummingMergeTree：这是一种特殊的MergeTree表引擎，它支持对某些列进行聚合操作，例如计算总和、平均值等。该引擎适用于需要经常对数据进行聚合操作的场景。")])]),e._v(" "),a("li",[a("p",[e._v("AggregatingMergeTree：这是另一种特殊的MergeTree表引擎，它支持对数据按照指定的粒度进行预先计算。该引擎适用于需要快速生成报表、统计数据等场景。")])]),e._v(" "),a("li",[a("p",[e._v("GraphiteMergeTree：这是一种特殊的MergeTree表引擎，它支持Graphite样式的时间序列数据，即将每个时间戳的值映射到一个路径中。该引擎适用于监控和指标收集等场景。")])])]),e._v(" "),a("h2",{attrs:{id:"hdfs-hadoop-distributed-file-system-是适合存储大型数据集的分布式文件系统"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#hdfs-hadoop-distributed-file-system-是适合存储大型数据集的分布式文件系统"}},[e._v("#")]),e._v(" HDFS（Hadoop Distributed File System）是适合存储大型数据集的分布式文件系统")]),e._v(" "),a("ol",[a("li",[e._v("块存储：HDFS将文件拆分成块（默认大小为128MB），并在不同的节点上进行复制存储，使得大型数据集可以轻松地存储和处理。这样做还有助于提高读取速度，因为多个节点可以并行读取不同的块。")]),e._v(" "),a("li",[e._v("容错性：如果某个节点失效，HDFS会自动重复该节点上的数据块。这种冗余设计可以保证数据的可靠性和容错性，防止数据丢失。")]),e._v(" "),a("li",[e._v("处理能力：HDFS与Hadoop生态系统的其他组件（如MapReduce和Spark）配合使用，可以对大型数据集进行高效的处理和分析。其能够并行处理海量数据集，大幅提升数据处理速度。")]),e._v(" "),a("li",[e._v("适用场景：HDFS适用于存储大型数据集，例如日志文件、传感器数据、图片、音频和视频等。这些数据集通常具有高度结构化或半结构化特征，不需要经常更新，但需要被反复访问和处理。")])]),e._v(" "),a("h2",{attrs:{id:"对于数据仓库的理解"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#对于数据仓库的理解"}},[e._v("#")]),e._v(" 对于数据仓库的理解")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[e._v("数据仓库是一个面向主题的、集成的、相对稳定的、反映历史变化（的数据集合，\n1. 对数据进行规划管理\n2. 利于后期的维护工作\n3. 保证数据更加清晰化\nODS层 dwd dws dim DWM层\n")])])]),a("h2",{attrs:{id:"hive-内部表和外部表之间的一些区别"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#hive-内部表和外部表之间的一些区别"}},[e._v("#")]),e._v(" Hive 内部表和外部表之间的一些区别")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[e._v("存储位置：内部表的数据存储在Hive仓库中，而外部表的数据存储在HDFS或其他存储系统中。\n\n表的定义：内部表的定义在Hive仓库中保留，并由Hive自动管理。而外部表的定义存储在Hive元数据库中，但数据本身并不属于Hive的控制范围之内。\n\n数据管理：当您删除内部表时，该表的数据也将被删除。但是，如果您删除一个外部表，它只会删除元数据信息，而不会删除数据本身。\n\n查询性能：内部表比外部表更快，因为它们存储在Hive仓库中，而不是外部存储中。\n\n数据导入：使用内部表可以方便地将数据从Hive仓库直接导入到内部表中，而使用外部表则需要先将数据导入到HDFS中，然后才能使用外部表访问数据。\n")])])]),a("h2",{attrs:{id:"hive-sql有哪三种分组排序-他们各自的特点是什么"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#hive-sql有哪三种分组排序-他们各自的特点是什么"}},[e._v("#")]),e._v(" Hive SQL有哪三种分组排序，他们各自的特点是什么")]),e._v(" "),a("ol",[a("li",[a("p",[e._v("SORT BY")]),e._v(" "),a("p",[e._v("使用SORT BY对数据进行排序，但不会改变数据分区。SORT BY语句是用于单个数据文件或多个数据文件的操作，并且可以与LIMIT子句一起使用来控制输出行数。")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[e._v("特点：\n\n它可以用来对数据进行排序。\n它不会更改数据的分布或分区。\n它可以与LIMIT子句一起使用，以便在输出数据之前限制结果集的大小。\n")])])])]),e._v(" "),a("li",[a("p",[e._v("ORDER BY")]),e._v(" "),a("p",[e._v("使用ORDER BY对数据进行排序，并将数据重新分配到不同的分区中。ORDER BY语句是一种全局排序技术，它可以用于任何查询。")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[e._v("特点：\n\n它可以用于对数据进行排序。\n它将进行全局排序，因此它可以更改数据的分布或分区。\n它不仅可以对数据进行排序，而且还可以指定升序或降序排序。\n")])])])]),e._v(" "),a("li",[a("p",[e._v("CLUSTER BY")]),e._v(" "),a("p",[e._v("使用CLUSTER BY对数据进行排序，并将数据重新分配到按照指定列排序的分区中。CLUSTER BY语句是一种本地排序技术，它只能用于创建表时定义的那些列。")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[e._v("特点：\n\n它可以用于对数据进行排序。\n它重新分配数据并在每个分区中对其进行排序。\n它只能基于表定义的列进行排序。\n")])])])])]),e._v(" "),a("h2",{attrs:{id:"udf-udaf-udtf-它们的区别是什么-请问它们分别解决了什么问题"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#udf-udaf-udtf-它们的区别是什么-请问它们分别解决了什么问题"}},[e._v("#")]),e._v(" UDF/UDAF/UDTF，它们的区别是什么，请问它们分别解决了什么问题")]),e._v(" "),a("ol",[a("li",[a("p",[e._v("UDF（User-Defined Function，用户自定义函数）")]),e._v(" "),a("p",[e._v("UDF是一种用于对"),a("strong",[e._v("单个输入行")]),e._v("进行转换的函数。它接受一个或多个输入参数，并返回一个输出值。UDF通常用于执行字符串操作、日期/时间操作、数学计算等。")])]),e._v(" "),a("li",[a("p",[e._v("UDAF（User-Defined Aggregation Function，用户自定义聚合函数）")]),e._v(" "),a("p",[e._v("UDAF是一种用于对"),a("strong",[e._v("一组数据行进行聚合处理")]),e._v("的函数。它接受一组输入值，并返回单个输出值。UDAF通常用于执行聚合操作，如计算平均值、最小值、最大值等。")])]),e._v(" "),a("li",[a("p",[e._v("UDTF（User-Defined Table-Generating Function，用户自定义表生成函数）")])])]),e._v(" "),a("p",[e._v("UDTF是一种用于"),a("strong",[e._v("生成多个输出行的函数")]),e._v("。它接受一个或多个输入参数，并生成一个或多个输出行。UDTF通常用于将单个输入行拆分成多个输出行，从而实现数据转换和重构。")]),e._v(" "),a("h2",{attrs:{id:"某些job运行时间较长可能是由于以下几个原因造成的"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#某些job运行时间较长可能是由于以下几个原因造成的"}},[e._v("#")]),e._v(" 某些Job运行时间较长可能是由于以下几个原因造成的")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[e._v("数据量过大：当处理的数据量非常大时，Job的运行时间可能会增加。这可能需要考虑对数据进行分片或者并行处理。\n\n复杂的计算逻辑：当Job涉及到复杂的计算逻辑时，运行时间也会增加。这可能需要优化代码以改进性能，例如使用更高效的算法、避免重复计算等。\n\n数据倾斜：在某些情况下，数据可能会不均匀地分布在各个节点上，导致某些节点负载过重。这可能需要进行数据倾斜处理，例如重新分区或者使用join操作时选择更合适的键值。\n\n针对这些问题，可以采取以下措施来缩短Job运行时间：\n\n分布式处理：使用分布式处理技术，如Hadoop MapReduce或Spark等，可以将数据分片并发处理，减少单个节点的负载和整体运行时间。\n\n优化算法：针对特定的计算问题，可以选择更高效的算法，尽可能避免重复计算。\n\n数据预处理：对于大规模数据处理任务，预处理数据可能会带来显著的性能提升。例如，可以先对数据进行归一化、筛选、剪枝等操作，以减少计算量和数据传输量。\n\n数据倾斜处理：对于数据倾斜问题，可以采取一些调整策略，例如重新分区、使用Combiner函数等，以平衡负载并减少计算时间。\n\n调整资源配置：合理调整集群资源配置，如CPU、内存、磁盘空间等，可以提高整体处理能力和运行效率。\n\n综上所述，通过优化算法、使用分布式技术、预处理数据、解决数据倾斜和调整资源配置等手段，可以有效缩短Job运行时间和提高处理效率。\n")])])]),a("h2",{attrs:{id:"如何解决数据倾斜问题"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#如何解决数据倾斜问题"}},[e._v("#")]),e._v(" 如何解决数据倾斜问题")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[e._v("数据倾斜是指在分布式计算环境中，数据被不均匀地分配到各个节点上，导致某些节点负载过重的问题。当数据倾斜发生时，会对整个计算作业的性能产生非常大的影响，甚至导致作业运行失败。以下是一些解决数据倾斜问题的方法：\n\n改变键值：如果在操作中使用的键值出现了数据倾斜问题，可以考虑使用其他键值进行操作，例如将复杂键值切分为多个简单键值，或者使用哈希函数来生成新的键值。\n\n重新分区：通过增加或减少分区的数量，可以使数据更均匀地分布在各个节点上。重新分区可以使用Hive的SKEW JOIN语法，或者使用Spark的repartition、coalesce函数等。\n\n广播小表：如果一个表很小而另一个表很大，可以将小表广播到所有节点上，以避免大表数据倾斜问题。广播可以使用Hive的MAPJOIN语法，或者使用Spark的broadcast函数。\n\n增加Combiner函数：Combiner函数类似于Map端的reduce函数，可以在Map输出阶段对数据进行合并和压缩，以减少数据传输量和节点间的交互次数。Combiner函数可以使用Hadoop的Combiner类或者Spark的combineByKey函数实现。\n\n调整硬件配置：如果节点之间的性能差异较大，可以调整硬件配置来平衡节点的负载。例如增加节点的CPU、内存、磁盘等资源，或者重新分配任务和数据。\n\n综上所述，数据倾斜问题可能由于多种原因引起，需要根据具体情况采用相应的解决办法。可以通过改变键值、重新分区、广播小表、增加Combiner函数、调整硬件配置等方式来解决数据倾斜问题，从而提高整个作业的性能和效率。\n")])])]),a("h2",{attrs:{id:"hive分区表的作用是什么-是否越多越好"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#hive分区表的作用是什么-是否越多越好"}},[e._v("#")]),e._v(" Hive分区表的作用是什么，是否越多越好")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[e._v("在Hive中，分区表是一种将数据分成更小、更管理的单元以提高查询性能和管理数据的方法。分区表将数据按照一个或多个分区键划分为不同的分区，并将每个分区存储在独立的目录中。每个分区都有一个唯一的标识符来标识它所属的分区。\n\nHive分区表的作用包括：\n\n提高查询性能：由于数据被分组到不同的分区中，因此可以仅针对需要的分区进行查询，从而减少查询的数据量和查询时间。\n\n管理数据：将数据分成更小、更可管理的单元，可以帮助用户更方便地管理和维护数据。\n\n支持并行处理：由于数据被分成了多个分区，因此可以同时处理多个分区，以实现更快的查询速度。\n\n支持动态分区：Hive支持动态创建分区，即可以根据数据中实际存在的值来自动创建新的分区。\n\n需要注意的是，虽然分区表可以提高查询性能和管理数据的效率，但这并不意味着分区越多越好。过多的分区会增加元数据的大小，并且可能导致查询性能下降。因此，在创建分区表时应该根据实际需求来决定采用多少个分区。\n\n通常情况下，应该将分区键选为经常用于查询的列，并且应该将分区数限制在一个合理的范围内。例如，可以将分区数设置为100-1000个左右，这样既可以满足查询需求，又可以避免出现过多的分区导致性能下降的问题。\n")])])]),a("h2",{attrs:{id:"flink有哪些时间语义-有哪些使用场景"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#flink有哪些时间语义-有哪些使用场景"}},[e._v("#")]),e._v(" Flink有哪些时间语义，有哪些使用场景？")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[e._v("    Event Time\n    Event Time是指在流中发生的真实时间戳，与数据生成的时间无关。它可以通过在数据中包含时间戳信息来实现，或者通过调用assignTimestampsAndWatermarks方法为数据分配时间戳。\n\n    使用Event Time时，窗口的划分基于事件时间而不是处理时间，使得它更容易处理延迟数据和乱序数据。例如，您可以使用Event Time对一些历史数据进行离线处理和分析。\n\n    Processing Time\n    Processing Time是指在流处理系统中处理数据的本地系统时间。它可以通过调用DataStream类的timeWindowAll或keyBy方法指定，不需要显式地给出时间戳信息。\n\n    使用Processing Time时，窗口的划分基于处理时间而不是事件时间。由于处理时间会随着系统负载的变化而变化，因此可能会导致窗口计算的结果不稳定。因此，在处理时间上做聚合或累加操作时，需要考虑到数据乱序和延迟问题。\n\n    Ingestion Time\n    Ingestion Time是指在流处理系统中读取数据并为其分配时间戳的时间。它可以通过调用DataStream类的assignTimestampsAndWatermarks方法指定，从而将时间戳信息包含在数据中。\n\n    使用Ingestion Time时，窗口的划分基于数据进入系统的时间。它既可以兼顾事件时间和处理时间的优点，又可以有效地处理数据乱序和延迟。\n")])])]),a("h2",{attrs:{id:"hdfs数据存储小文件问题"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#hdfs数据存储小文件问题"}},[e._v("#")]),e._v(" HDFS数据存储小文件问题")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[e._v("    在HDFS数据存储中，小文件问题指的是存储了大量小型文件（通常是几百KB或更小），这些小文件可能会对系统性能和可靠性造成严重影响。下面是小文件带来的一些危害：\n\n    占用大量存储空间：每个文件都需要至少一个块（通常为128MB），即使文件实际大小远小于块大小，也会占用整个块的存储空间。因此，小文件消耗的存储空间远大于它们的实际大小。\n\n    影响系统性能：磁盘I/O操作是HDFS中的瓶颈之一，而小文件数量多时，将导致大量的小的磁盘读取/写入操作，从而导致系统性能下降。此外，在处理小文件时，还需要频繁打开和关闭文件句柄，这也会对系统性能产生不利影响。\n\n    增加数据管理难度：小文件数目多时，系统的元数据管理开销也会增加，例如文件名、权限等属性。由于元数据的管理是单点故障，因此管理大量小文件可能会导致元数据服务器过载或故障。\n\n    降低数据可靠性：与大文件相比，小文件的校验开销较大，且容易受到网络传输错误和存储介质损坏等因素的影响，从而导致数据可靠性降低。\n\n    综上所述，小文件问题会对HDFS系统的存储效率、读写性能、数据管理和可靠性等方面产生不利影响。因此，在实践中应该尽量避免存储大量小文件，可以通过合并小文件、打包文件、使用SequenceFile等方式来优化处理存储小文件的问题。\n")])])])])}),[],!1,null,null,null);a.default=n.exports}}]);